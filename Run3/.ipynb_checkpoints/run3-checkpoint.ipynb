{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Scene_Recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9424\\1968422405.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mScene_Recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Scene_Recognition'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from Scene_Recognition.functions import *\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "script_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "dataset_path = os.path.join(script_dir, \"..\", \"training\")\n",
    "links, labels = load_dataset(dataset_path)\n",
    "\n",
    "feature_vectors = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AlexNet model\n",
    "def create_alexnet(input_shape=(227, 227, 3), num_classes=10):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(layers.Conv2D(96, (11, 11), strides=(4, 4), input_shape=input_shape, padding='valid', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(layers.Conv2D(256, (5, 5), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 4\n",
    "    model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n",
    "\n",
    "    # Layer 5\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((3, 3), strides=(2, 2)))\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "alexnet = create_alexnet()\n",
    "\n",
    "# Display the model summary\n",
    "alexnet.summary()\n",
    "\n",
    "# Compile the model\n",
    "alexnet.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if your labels are one-hot encoded\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "# Assuming you have X_train, y_train, X_test, y_test\n",
    "\n",
    "# Train the model\n",
    "alexnet.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "# Example of loading and preprocessing 10 images\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# image_paths = [\"path_to_image1.jpg\", \"path_to_image2.jpg\", ...]  # Provide the paths to your images\n",
    "# images = [cv2.resize(cv2.imread(path), (227, 227)) for path in image_paths]\n",
    "# images = np.array(images) / 255.0  # Normalize the pixel values to the range [0, 1]\n",
    "\n",
    "# Perform inference on the images\n",
    "predictions = alexnet.predict(images)\n",
    "\n",
    "# Print the predictions for each image\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Image {i + 1} - Predicted class: {np.argmax(prediction)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
